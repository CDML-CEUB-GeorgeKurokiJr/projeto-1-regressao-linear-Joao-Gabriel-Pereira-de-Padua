{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting kagglehub\n",
      "  Downloading kagglehub-1.0.0-py3-none-any.whl.metadata (40 kB)\n",
      "     ---------------------------------------- 0.0/40.1 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 10.2/40.1 kB ? eta -:--:--\n",
      "     ------------------- ------------------ 20.5/40.1 kB 217.9 kB/s eta 0:00:01\n",
      "     -------------------------------------- 40.1/40.1 kB 271.1 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: statsmodels in c:\\programdata\\anaconda3\\lib\\site-packages (0.14.2)\n",
      "Requirement already satisfied: numpy<2 in c:\\programdata\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Collecting kagglesdk<1.0,>=0.1.14 (from kagglehub)\n",
      "  Downloading kagglesdk-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub) (23.2)\n",
      "Requirement already satisfied: pyyaml in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: protobuf in c:\\programdata\\anaconda3\\lib\\site-packages (from kagglesdk<1.0,>=0.1.14->kagglehub) (3.20.3)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2024.7.4)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-1.0.0-py3-none-any.whl (70 kB)\n",
      "   ---------------------------------------- 0.0/70.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 70.6/70.6 kB 1.9 MB/s eta 0:00:00\n",
      "Downloading kagglesdk-0.1.15-py3-none-any.whl (160 kB)\n",
      "   ---------------------------------------- 0.0/160.4 kB ? eta -:--:--\n",
      "   -------------------------------------- - 153.6/160.4 kB 4.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 160.4/160.4 kB 2.4 MB/s eta 0:00:00\n",
      "Installing collected packages: kagglesdk, kagglehub\n",
      "Successfully installed kagglehub-1.0.0 kagglesdk-0.1.15\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub pandas scikit-learn statsmodels \"numpy<2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixando dataset...\n",
      "Downloading to C:\\Users\\llib.322\\.cache\\kagglehub\\datasets\\mlg-ulb\\creditcardfraud\\3.archive...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66.0M/66.0M [00:22<00:00, 3.11MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base carregada! Temos 284807 transações.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"Baixando dataset...\")\n",
    "path = kagglehub.dataset_download(\"mlg-ulb/creditcardfraud\")\n",
    "csv_file = [f for f in os.listdir(path) if f.endswith('.csv')][0]\n",
    "df = pd.read_csv(os.path.join(path, csv_file))\n",
    "\n",
    "print(f\"Base carregada! Temos {df.shape[0]} transações.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados padronizados e prontos para o modelo!\n"
     ]
    }
   ],
   "source": [
    "# Padronizando Time e Amount\n",
    "scaler = StandardScaler()\n",
    "df['Time_Scaled'] = scaler.fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "df['Amount_Scaled'] = scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "# Removendo as colunas antigas e definindo X e y\n",
    "df = df.drop(columns=['Time', 'Amount'])\n",
    "\n",
    "# O Alvo é a coluna Class (0 ou 1)\n",
    "y = df['Class']\n",
    "X = df.drop(columns=['Class'])\n",
    "\n",
    "print(\"Dados padronizados e prontos para o modelo!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando o modelo de Regressão Linear Clássica...\n",
      "\n",
      "========================================\n",
      " RESULTADOS: REGRESSÃO LINEAR\n",
      "========================================\n",
      "AUPRC Score: 0.7196\n",
      "\n",
      "Matriz de Confusão (Usando Limiar de 0.5):\n",
      "Transações Legítimas identificadas corretamente: 56851\n",
      "Transações Legítimas bloqueadas por engano (Falso Positivo): 13\n",
      "FRAUDES que passaram direto (Falso Negativo): 53  <-- O PESADELO DO BANCO\n",
      "FRAUDES bloqueadas corretamente: 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import average_precision_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Separação em Treino e Teste (Estratificado para manter a proporção de fraudes)\n",
    "# Usaremos o mesmo random_state para a comparação ser justa\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Treinando o modelo de Regressão Linear Clássica...\")\n",
    "modelo_linear = LinearRegression()\n",
    "modelo_linear.fit(X_train, y_train)\n",
    "\n",
    "# 1. O modelo gera as previsões contínuas (ex: -0.1, 0.4, 0.9)\n",
    "y_pred_continuo = modelo_linear.predict(X_test)\n",
    "\n",
    "# 2. O \"Hack\" do Limiar: Tudo >= 0.5 vira 1 (Fraude). O resto vira 0.\n",
    "limiar = 0.5\n",
    "y_pred_binario = (y_pred_continuo >= limiar).astype(int)\n",
    "\n",
    "# Avaliação usando AUPRC (Usamos o valor contínuo como se fosse o \"grau de certeza\")\n",
    "auprc = average_precision_score(y_test, y_pred_continuo)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\" RESULTADOS: REGRESSÃO LINEAR\")\n",
    "print(\"=\"*40)\n",
    "print(f\"AUPRC Score: {auprc:.4f}\")\n",
    "\n",
    "print(\"\\nMatriz de Confusão (Usando Limiar de 0.5):\")\n",
    "cm = confusion_matrix(y_test, y_pred_binario)\n",
    "print(f\"Transações Legítimas identificadas corretamente: {cm[0][0]}\")\n",
    "print(f\"Transações Legítimas bloqueadas por engano (Falso Positivo): {cm[0][1]}\")\n",
    "print(f\"FRAUDES que passaram direto (Falso Negativo): {cm[1][0]}  <-- O PESADELO DO BANCO\")\n",
    "print(f\"FRAUDES bloqueadas corretamente: {cm[1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTANDO DIFERENTES LIMIARES (THRESHOLDS) NA REGRESSÃO LINEAR\n",
      "============================================================\n",
      "--- Limiar de Corte: 0.05 ---\n",
      "FRAUDES PEGAs com sucesso: 80\n",
      "Fraudes perdidas (Prejuízo): 18\n",
      "Cartões bloqueados por engano (Irritação do cliente): 23\n",
      "------------------------------\n",
      "--- Limiar de Corte: 0.1 ---\n",
      "FRAUDES PEGAs com sucesso: 80\n",
      "Fraudes perdidas (Prejuízo): 18\n",
      "Cartões bloqueados por engano (Irritação do cliente): 23\n",
      "------------------------------\n",
      "--- Limiar de Corte: 0.2 ---\n",
      "FRAUDES PEGAs com sucesso: 80\n",
      "Fraudes perdidas (Prejuízo): 18\n",
      "Cartões bloqueados por engano (Irritação do cliente): 20\n",
      "------------------------------\n",
      "--- Limiar de Corte: 0.3 ---\n",
      "FRAUDES PEGAs com sucesso: 72\n",
      "Fraudes perdidas (Prejuízo): 26\n",
      "Cartões bloqueados por engano (Irritação do cliente): 17\n",
      "------------------------------\n",
      "--- Limiar de Corte: 0.4 ---\n",
      "FRAUDES PEGAs com sucesso: 56\n",
      "Fraudes perdidas (Prejuízo): 42\n",
      "Cartões bloqueados por engano (Irritação do cliente): 13\n",
      "------------------------------\n",
      "--- Limiar de Corte: 0.5 ---\n",
      "FRAUDES PEGAs com sucesso: 45\n",
      "Fraudes perdidas (Prejuízo): 53\n",
      "Cartões bloqueados por engano (Irritação do cliente): 13\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"TESTANDO DIFERENTES LIMIARES (THRESHOLDS) NA REGRESSÃO LINEAR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Vamos testar limites desde 0.05 até 0.5\n",
    "limiares_para_testar = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "\n",
    "for limiar in limiares_para_testar:\n",
    "    # Transforma em 1 (Fraude) tudo que for maior que o limiar atual\n",
    "    y_pred_simulado = (y_pred_continuo >= limiar).astype(int)\n",
    "    cm = confusion_matrix(y_test, y_pred_simulado)\n",
    "    \n",
    "    fraudes_pegas = cm[1][1]\n",
    "    fraudes_perdidas = cm[1][0]\n",
    "    cartoes_bloqueados_engano = cm[0][1]\n",
    "    \n",
    "    print(f\"--- Limiar de Corte: {limiar} ---\")\n",
    "    print(f\"FRAUDES PEGAs com sucesso: {fraudes_pegas}\")\n",
    "    print(f\"Fraudes perdidas (Prejuízo): {fraudes_perdidas}\")\n",
    "    print(f\"Cartões bloqueados por engano (Irritação do cliente): {cartoes_bloqueados_engano}\")\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICANDO UNDERSAMPLING PARA BALANCEAR OS DADOS...\n",
      "Novo tamanho do treino: 788 linhas (50% Fraude / 50% Legítimo).\n",
      "\n",
      "========================================\n",
      " RESULTADOS: REGRESSÃO LINEAR COM UNDERSAMPLING\n",
      "========================================\n",
      "FRAUDES PEGAs com sucesso: 82\n",
      "Fraudes perdidas (Prejuízo): 16\n",
      "Cartões bloqueados por engano (Irritação do cliente): 900\n",
      "Transações Legítimas identificadas corretamente: 55964\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "print(\"APLICANDO UNDERSAMPLING PARA BALANCEAR OS DADOS...\")\n",
    "\n",
    "# 1. Juntamos o X_train e y_train para facilitar a manipulação\n",
    "df_train = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# 2. Separamos as fraudes e as transações legítimas\n",
    "fraudes = df_train[df_train['Class'] == 1]\n",
    "legitimas = df_train[df_train['Class'] == 0]\n",
    "\n",
    "# 3. Sorteamos aleatoriamente transações legítimas na mesma quantidade de fraudes\n",
    "legitimas_undersampled = resample(\n",
    "    legitimas, \n",
    "    replace=False,           # Sem repetição\n",
    "    n_samples=len(fraudes),  # Exatamente o mesmo número de fraudes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 4. Juntamos tudo em um novo dataset de treino 50/50\n",
    "df_train_balanceado = pd.concat([fraudes, legitimas_undersampled])\n",
    "\n",
    "# Separamos de volta em X e y para o modelo\n",
    "X_train_bal = df_train_balanceado.drop('Class', axis=1)\n",
    "y_train_bal = df_train_balanceado['Class']\n",
    "\n",
    "print(f\"Novo tamanho do treino: {len(X_train_bal)} linhas (50% Fraude / 50% Legítimo).\")\n",
    "\n",
    "# 5. Treinando a Nova Regressão Linear\n",
    "modelo_balanceado = LinearRegression()\n",
    "modelo_balanceado.fit(X_train_bal, y_train_bal)\n",
    "\n",
    "# Previsões nos dados de TESTE originais (que continuam desbalanceados, a vida real!)\n",
    "y_pred_cont_bal = modelo_balanceado.predict(X_test)\n",
    "\n",
    "# Como a base agora é 50/50, o limiar natural de 0.5 volta a fazer sentido matemático\n",
    "y_pred_bin_bal = (y_pred_cont_bal >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\" RESULTADOS: REGRESSÃO LINEAR COM UNDERSAMPLING\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "cm_bal = confusion_matrix(y_test, y_pred_bin_bal)\n",
    "print(f\"FRAUDES PEGAs com sucesso: {cm_bal[1][1]}\")\n",
    "print(f\"Fraudes perdidas (Prejuízo): {cm_bal[1][0]}\")\n",
    "print(f\"Cartões bloqueados por engano (Irritação do cliente): {cm_bal[0][1]}\")\n",
    "print(f\"Transações Legítimas identificadas corretamente: {cm_bal[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICANDO SMOTE (OVERSAMPLING INTELIGENTE)...\n",
      "Novo tamanho do treino: 454902 linhas.\n",
      "Fraudes: 227451 | Legítimas: 227451\n",
      "\n",
      "========================================\n",
      " RESULTADOS: REGRESSÃO LINEAR COM SMOTE\n",
      "========================================\n",
      "FRAUDES PEGAs com sucesso: 85\n",
      "Fraudes perdidas (Prejuízo): 13\n",
      "Cartões bloqueados por engano (Irritação do cliente): 794\n",
      "Transações Legítimas identificadas corretamente: 56070\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "print(\"APLICANDO SMOTE (OVERSAMPLING INTELIGENTE)...\")\n",
    "\n",
    "# Inicializa o SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# A regra de ouro: aplicamos o balanceamento APENAS nos dados de TREINO.\n",
    "# O teste (y_test) tem que continuar sendo a vida real (desbalanceado).\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f\"Novo tamanho do treino: {len(X_train_smote)} linhas.\")\n",
    "print(f\"Fraudes: {sum(y_train_smote == 1)} | Legítimas: {sum(y_train_smote == 0)}\")\n",
    "\n",
    "# Treinando a Regressão Linear na base gigante e balanceada\n",
    "modelo_smote = LinearRegression()\n",
    "modelo_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Previsão nos dados de Teste intocados\n",
    "y_pred_cont_smote = modelo_smote.predict(X_test)\n",
    "\n",
    "# Limiar de 0.5 (como a base de treino era 50/50, o meio é o ponto de corte ideal)\n",
    "y_pred_bin_smote = (y_pred_cont_smote >= 0.5).astype(int)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\" RESULTADOS: REGRESSÃO LINEAR COM SMOTE\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "cm_smote = confusion_matrix(y_test, y_pred_bin_smote)\n",
    "print(f\"FRAUDES PEGAs com sucesso: {cm_smote[1][1]}\")\n",
    "print(f\"Fraudes perdidas (Prejuízo): {cm_smote[1][0]}\")\n",
    "print(f\"Cartões bloqueados por engano (Irritação do cliente): {cm_smote[0][1]}\")\n",
    "print(f\"Transações Legítimas identificadas corretamente: {cm_smote[0][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando o VIF para provar o efeito do PCA...\n",
      "\n",
      "--- RESULTADO DO TESTE VIF (A Mágica do PCA) ---\n",
      "Variável      VIF\n",
      "      V1 1.000126\n",
      "      V2 1.000098\n",
      "      V3 1.000167\n",
      "      V4 1.000070\n",
      "      V5 1.000220\n",
      "      V6 1.000055\n",
      "      V7 1.000238\n",
      "      V8 1.000102\n",
      "      V9 1.000058\n",
      "     V10 1.000094\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Calculando o VIF para provar o efeito do PCA...\")\n",
    "\n",
    "# Pegamos apenas as colunas de V1 a V28\n",
    "colunas_pca = [f'V{i}' for i in range(1, 29)]\n",
    "X_pca = X_train[colunas_pca]\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variável\"] = X_pca.columns\n",
    "\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_pca.values, i) for i in range(X_pca.shape[1])]\n",
    "\n",
    "print(\"\\n--- RESULTADO DO TESTE VIF (A Mágica do PCA) ---\")\n",
    "print(vif_data.head(10).to_string(index=False)) # Mostrando as 10 primeiras para não poluir a tela\n",
    "print(\"...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
